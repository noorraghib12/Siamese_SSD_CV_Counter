{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c91fbf7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import dlib\n",
    "import cv2\n",
    "import time\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from scipy.spatial import distance as dist\n",
    "from collections import OrderedDict\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus: \n",
    "    tf.config.experimental.set_memory_growth(gpu, True)\n",
    "\n",
    "\n",
    "label_map= [\"ep_black\",\"ep_green\",\"ep_orange\"]\n",
    "label_map.sort()\n",
    "detect_fn=tf.saved_model.load(\".\\\\saved_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "726d1714",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.saved_model.load.Loader._recreate_base_user_object.<locals>._UserObject at 0x116b50da788>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detect_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d77e336",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "from tensorflow.keras.applications import resnet50\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Flatten \n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import load_model\n",
    " \n",
    "# load class model\n",
    "class_model = load_model('.\\\\imageacc_model.h5')\n",
    "\n",
    "#Backbone_SNN\n",
    "# base_resnet=tf.keras.applications.ResNet50(include_top=False,weights=\"imagenet\",input_shape=(150,150,3),classes=len(label_map))\n",
    "# # for i in base_resnet.layers[:(math.ceil(len(base_resnet.layers)/2))]:\n",
    "# #     i.trainable=False\n",
    "# conv1=Conv2D(48,(1,1),padding=\"valid\",activation=\"relu\")\n",
    "# dr1=layers.Dropout(0.3)\n",
    "# avgpool1 = tf.keras.layers.AveragePooling2D(pool_size=(2, 2))\n",
    "# conv2=Conv2D(78,(1,1),padding=\"same\",activation=\"relu\")\n",
    "# dr2=layers.Dropout(0.2)\n",
    "# flatten_layer = Flatten()\n",
    "# dense1 = Dense(108,activation='sigmoid')\n",
    "\n",
    "# embedding_model=tf.keras.Sequential([base_resnet,conv1,avgpool1,conv2,flatten_layer,dense1])\n",
    "# embedding_model.load_weights(\".\\\\checkpoint_94_0.00.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e8facc30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " sequential_5 (Sequential)   (None, 108)               23723690  \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 3)                 327       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 23,724,017\n",
      "Trainable params: 327\n",
      "Non-trainable params: 23,723,690\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "class_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af7dcde9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_boxes(frame, detect_fn,thresh,H,W):\n",
    "        image_np = np.array(frame)\n",
    "        input_tensor = tf.convert_to_tensor(np.expand_dims(image_np, 0), dtype=tf.uint8)\n",
    "        detections = detect_fn(input_tensor)\n",
    "        # detection_classes should be ints.\n",
    "        score_mask=(detections['detection_scores']>0.5).numpy().reshape(-1)\n",
    "        rects_masked=detections['detection_boxes'].numpy().reshape(100,4)[score_mask]\n",
    "        rects=(rects_masked*np.array([H,W,H,W])).astype(int)\n",
    "        func=lambda x: (x[1]+x[3])/2\n",
    "        rect_mask=np.array(list(map(func,rects)))>600*0.30\n",
    "        print(rects)\n",
    "        print(rect_mask)\n",
    "        valid_rects=rects[rect_mask]\n",
    "        print(\"Valid_rects\\n {}\".format(valid_rects))\n",
    "        return valid_rects\n",
    "    \n",
    "def visualize_boxes(image,tracks):    \n",
    "    for id_,track in tracks.items():\n",
    "        (startY,startX,endY,endX) = track.box\n",
    "        name=\"unknown\" if track.name==None else track.name\n",
    "        # draw the bounding box of the face along with the associated probability\n",
    "        cv2.rectangle(image, (startX, startY), (endX, endY), (0, 0, 255), 2)\n",
    "        cv2.putText(image, name, (startX, startY),cv2.FONT_HERSHEY_SIMPLEX, 0.65, (255, 255, 255), 2)\n",
    "        #cv2.putText(image, name, (startX, startY),cv2.FONT_HERSHEY_SIMPLEX, 0.45, (255, 255,255), 2) \n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "38d6686f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# def get_name(model,svm,face_pixels,label_map):\n",
    "#     img=cv2.resize(face_pixels,(160,160))\n",
    "#     img = np.around(np.array(img) / 255.0, decimals=12)\n",
    "#     x_train = np.expand_dims(img, axis=0)\n",
    "#     embedding = model.predict(x_train)\n",
    "#     embedding= embedding / np.linalg.norm(embedding, ord=2)\n",
    "#     name=svm.predict(embedding.reshape(1,-1))\n",
    "#     return label_map[name]\n",
    "\n",
    "\n",
    "\n",
    "class Track():\n",
    "    def __init__(self,tracker,box):\n",
    "        self.tracker=tracker\n",
    "        self.box=box\n",
    "        self.recognized_face=False\n",
    "        self.encodings=None \n",
    "        self.name=None\n",
    "        self.prob_face={}\n",
    "        self.centroid=self.get_centroid()\n",
    "        self.rec_count=0\n",
    "        #self.spoof_confirm=[]\n",
    "\n",
    "\n",
    "    def update_track(self,frame):\n",
    "        self.tracker.update(frame)\n",
    "        pos=self.tracker.get_position()\n",
    "        startX = int(pos.left())\n",
    "        startY = int(pos.top())\n",
    "        endX = int(pos.right())\n",
    "        endY = int(pos.bottom())\n",
    "        tracked_box=np.array([startY,startX,endY,endX])\n",
    "        print(\"tracked_box\")\n",
    "        #print((\"tracked_box\",tracked_box))\n",
    "        prev_box=np.array(self.box)\n",
    "        #self.box=tracked_box.astype('int')\n",
    "        return tracked_box\n",
    "        #print((\"prev_box\",prev_box))\n",
    "        #self.box=self.box if get_overlap(tracked_box,prev_box)>0.95 else tracked_box.astype('int')\n",
    "        \n",
    "    def box_recognize(self,image,class_model,label_map,tracker):\n",
    "        global W,H\n",
    "        if (self.name==None and 0.46*W<self.get_centroid()[1]<0.50*W):\n",
    "            starty,startx,endy,endx=self.box\n",
    "            box_roi = image[starty:endy,startx:endx]  \n",
    "            img=cv2.cvtColor(box_roi,cv2.COLOR_BGR2RGB)\n",
    "            im = Image.fromarray(img, 'RGB')\n",
    "            #Resizing into dimensions you used\n",
    "            im = im.resize((150,150))\n",
    "            img_array = (np.array(im).astype(np.float32)/255)\n",
    "            #Expand dimensions to match the 4 D Tensor shape.\n",
    "            img_array = np.expand_dims(img_array, axis = 0)\n",
    "            idx_=class_model.predict(img_array)\n",
    "            name=label_map[np.argmax(idx_)]\n",
    "            self.name=name\n",
    "            tracker.count[name]=tracker.count.get(name,0)+1\n",
    "            print(tracker.count)\n",
    "    def get_box(self):\n",
    "        pos=self.tracker.get_position()\n",
    "        return [int(pos.left()),int(pos.top()),int(pos.right()),int(pos.bottom())]\n",
    "\n",
    "\n",
    "    def get_centroid(self):\n",
    "        box=self.box\n",
    "        return (int((box[0]+box[2])/2),int((box[1]+box[3])/2))\n",
    "\n",
    "\n",
    "class Tracker():\n",
    "    \n",
    "    global frame\n",
    "    \n",
    "    def __init__(self, maxDisappeared=5,maxDistance=150,thresh=None):\n",
    "        # initialize the next unique object ID along with two ordered\n",
    "        # dictionaries used to keep track of mapping a given object\n",
    "        # ID to its centroid and number of consecutive frames it has\n",
    "        # been marked as \"disappeared\", respectively\n",
    "        self.nextObjectID = 0\n",
    "        self.objects = OrderedDict()\n",
    "        self.disappeared = OrderedDict()\n",
    "        self.count={}\n",
    "        self.thresh=thresh\n",
    "        # store the number of maximum consecutive frames a given\n",
    "        # object is allowed to be marked as \"disappeared\" until we\n",
    "        # need to deregister the object from tracking\n",
    "        self.maxDisappeared = maxDisappeared\n",
    "        self.maxDistance=maxDistance\n",
    "\n",
    "    def register(self, rect,frame):\n",
    "    \n",
    "        # when registering an object we use the next available object\n",
    "        # ID to store the centroid\n",
    "        t = dlib.correlation_tracker()\n",
    "        (startY, startX, endY, endX)=rect\n",
    "        drect = dlib.rectangle(startX, startY, endX, endY)\n",
    "        t.start_track(frame, drect)\n",
    "        name='obj_'+str(self.nextObjectID)\n",
    "        self.objects[name] = Track(t,rect)\n",
    "        self.disappeared[name] = 0\n",
    "        self.nextObjectID+=1\n",
    "\n",
    "    def deregister(self, objectID):\n",
    "        # to deregister an object ID we delete the object ID from\n",
    "        # both of our respective dictionaries\n",
    "        trk=self.objects[objectID]\n",
    "        startY,startX,endY,endX=trk.box\n",
    "        print(\"vanishing_arr: {}\".format(trk.box))\n",
    "#         if int(startX/2+endX/2) <self.thresh:     \n",
    "#             name=trk.name\n",
    "#             self.count[name]=self.count.get(name,0)+1\n",
    "        del self.objects[objectID]\n",
    "        del self.disappeared[objectID]\n",
    "        \n",
    "    def deregister(self, objectID):\n",
    "        # to deregister an object ID we delete the object ID from\n",
    "        # both of our respective dictionaries\n",
    "#         trk=self.objects[objectID]\n",
    "#         startY,startX,endY,endX=trk.box\n",
    "#         if int(startX/2+endX/2) <self.thresh:     \n",
    "#             name=trk.name\n",
    "#             self.count[name]=self.count.get(name,0)+1\n",
    "            \n",
    "        del self.objects[objectID]\n",
    "        del self.disappeared[objectID]\n",
    "        \n",
    "    def track_update(self,frame):\n",
    "        height,width,channel = frame.shape\n",
    "        for objectID in list(self.disappeared.keys()):\n",
    "            trk=self.objects[objectID]\n",
    "            startY,startX,endY,endX=trk.box\n",
    "            if int(startX/2+endX/2)<(0.35*width):\n",
    "                self.disappeared[objectID]+=4.7\n",
    "            if self.disappeared[objectID]>self.maxDisappeared:\n",
    "                self.deregister(objectID)\n",
    "        t_rects=[]\n",
    "        for name in self.objects.keys():\n",
    "            t_rect=self.objects[name].update_track(frame)\n",
    "            t_rects.append(t_rect)\n",
    "        return np.array(t_rects)\n",
    "\n",
    "\n",
    "    def update(self,frame, coords,thresh):\n",
    "        \n",
    "        for objectID in list(self.disappeared.keys()):\n",
    "            trk=self.objects[objectID]\n",
    "            if trk.centroid[0]<thresh:\n",
    "                self.disappeared[objectID]+=1.7\n",
    "        \n",
    "        \n",
    "        \n",
    "        if len(coords) == 0:\n",
    "            # loop over any existing tracked objects and mark them\n",
    "            # as disappeared\n",
    "            for objectID in list(self.disappeared.keys()):\n",
    "                self.disappeared[objectID] += 1\n",
    "\n",
    "                # if we have reached a maximum number of consecutive\n",
    "                # frames where a given object has been marked as\n",
    "                # missing, deregister it\n",
    "                if self.disappeared[objectID] > self.maxDisappeared:\n",
    "                    self.deregister(objectID)\n",
    "\n",
    "            # return early as there are no centroids or tracking info\n",
    "            # to update\n",
    "            return self.objects\n",
    "        inputCentroids = np.zeros((len(coords), 2), dtype=\"int\")\n",
    "\n",
    "        # loop over the bounding box rectangles\n",
    "        for (i, (startY, startX, endY, endX)) in enumerate(coords):\n",
    "            # use the bounding box coordinates to derive the centroid\n",
    "            cX = int((startX + endX) / 2.0)\n",
    "            cY = int((startY + endY) / 2.0)\n",
    "            inputCentroids[i] = (cX, cY)\n",
    "\n",
    "        # initialize an array of input centroids for the current frame\n",
    "        \n",
    "        # if we are currently not tracking any objects take the input\n",
    "        # centroids and register each of them\n",
    "\n",
    "        if len(self.objects) == 0:\n",
    "            for i in range(0, len(coords)):\n",
    "                self.register(coords[i],frame)\n",
    "            \n",
    "            \n",
    "        # otherwise, are are currently tracking objects so we need to\n",
    "        # try to match the input centroids to existing object\n",
    "        # centroids\n",
    "        else:\n",
    "            # grab the set of object IDs and corresponding centroids\n",
    "            object_copy=self.objects.copy()\n",
    "            tracks_copy=list(object_copy.values())\n",
    "            #print('tracks:'+str(tracks_copy))\n",
    "            objectIDs = list(object_copy.keys())\n",
    "            #print('objectIDs:' + str(objectIDs))\n",
    "            objectCentroids = [i.centroid for i in tracks_copy]\n",
    "\n",
    "            # compute the distance between each pair of object\n",
    "            # centroids and input centroids, respectively -- our\n",
    "            # goal will be to match an input centroid to an existing\n",
    "            # object centroid\n",
    "            D = dist.cdist(np.array(objectCentroids), inputCentroids)\n",
    "\n",
    "            # in order to perform this matching we must (1) find the\n",
    "            # smallest value in each row and then (2) sort the row\n",
    "            # indexes based on their minimum values so that the row\n",
    "            # with the smallest value as at the *front* of the index\n",
    "            # list\n",
    "            rows = D.min(axis=1).argsort()\n",
    "            # next, we perform a similar process on the columns by\n",
    "            # finding the smallest value in each column and then\n",
    "            # sorting using the previously computed row index list\n",
    "            cols = D.argmin(axis=1)[rows]\n",
    "            \n",
    "            # in order to determine if we need to update, register,\n",
    "            # or deregister an object we need to keep track of which\n",
    "            # of the rows and column indexes we have already examined\n",
    "            usedRows = set()\n",
    "            usedCols = set()\n",
    "\n",
    "            # loop over the combination of the (row, column) index\n",
    "            # tuples\n",
    "            for (row, col) in zip(rows, cols):\n",
    "                # if we have already examined either the row or\n",
    "                # column value before, ignore it\n",
    "                # val\n",
    "                if row in usedRows or col in usedCols:\n",
    "                    continue\n",
    "                # if the distance between centroids is greater than\n",
    "                # the maximum distance, do not associate the two\n",
    "                # centroids to the same object\n",
    "                if D[row, col] > self.maxDistance:\n",
    "                    continue\n",
    "\n",
    "                # otherwise, grab the object ID for the current row,\n",
    "                # set its new centroid, and reset the disappeared\n",
    "                # counter\n",
    "                objectID = objectIDs[row]\n",
    "                prev_name=self.objects[objectID].name\n",
    "                prev_recog_state=self.objects[objectID].recognized_face\n",
    "                t = dlib.correlation_tracker()\n",
    "                (y1,x1,y2,x2)=coords[col]\n",
    "                #name=names[col]\n",
    "                rect=coords[col]\n",
    "                drect = dlib.rectangle(int(x1),int(y1),int(x2),int(y2))\n",
    "                t.start_track(frame, drect)\n",
    "                n_track=Track(t,rect)\n",
    "                self.objects[objectID] = n_track\n",
    "                self.objects[objectID].name=prev_name\n",
    "                self.objects[objectID].recognized_face=prev_recog_state\n",
    "                #self.objects[objectID].box = coords[col]\n",
    "                self.disappeared[objectID] = 0\n",
    "\n",
    "                # indicate that we have examined each of the row and\n",
    "                # column indexes, respectively\n",
    "                usedRows.add(row)\n",
    "                usedCols.add(col)\n",
    "\n",
    "            # compute both the row and column index we have NOT yet\n",
    "            # examined\n",
    "            unusedRows = set(range(0, D.shape[0])).difference(usedRows)\n",
    "            unusedCols = set(range(0, D.shape[1])).difference(usedCols)\n",
    "\n",
    "            # in the event that the number of object centroids is\n",
    "            # equal or greater than the number of input centroids\n",
    "            # we need to check and see if some of these objects have\n",
    "            # potentially disappeared\n",
    "            if D.shape[0] >= D.shape[1]:\n",
    "                # loop over the unused row indexes\n",
    "                for row in unusedRows:\n",
    "                    # grab the object ID for the corresponding row\n",
    "                    # index and increment the disappeared counter\n",
    "                    objectID = objectIDs[row]\n",
    "                    self.disappeared[objectID] += 1\n",
    "\n",
    "                    # check to see if the number of consecutive\n",
    "                    # frames the object has been marked \"disappeared\"\n",
    "                    # for warrants deregistering the object\n",
    "                    if self.disappeared[objectID] > self.maxDisappeared:\n",
    "                        self.deregister(objectID)\n",
    "\n",
    "            # otherwise, if the number of input centroids is greater\n",
    "            # than the number of existing object centroids we need to\n",
    "            # register each new input centroid as a trackable object\n",
    "            else:\n",
    "                for col in unusedCols:\n",
    "                    self.register(coords[col],frame)\n",
    "\n",
    "        # return the set of trackable objects\n",
    "        return self.objects\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d691b651",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "height: 337, width: 600\n"
     ]
    }
   ],
   "source": [
    "import imutils\n",
    "import time\n",
    "from PIL import Image\n",
    "cap=cv2.VideoCapture(\".\\\\testing_videos\\\\short_6.mp4\")\n",
    "#if vid_path:\n",
    "    #cap=cv2.VideoCapture(r'G:\\Wondershare UniConverter\\Converted\\ch01_20210707001338.mp4')\n",
    "#else:\n",
    "\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "W = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "H = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "#out = cv2.VideoWriter('full_output.avi',cv2.VideoWriter_fourcc('M','J','P','G'), fps, (W,H))\n",
    "fc=0\n",
    "thresh=int(600*0.30)\n",
    "tic=time.time()\n",
    "name_thresh=600*0.50\n",
    "tracker=Tracker(maxDisappeared=2,maxDistance=150,thresh=thresh)\n",
    "func=lambda x: (x[1]+x[3])/2\n",
    "FPS=[]\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    start=time.time()\n",
    "    img=cv2.cvtColor(frame,cv2.COLOR_BGR2RGB)\n",
    "    im = Image.fromarray(img, 'RGB')\n",
    "            #Resizing into dimensions you used\n",
    "    im = im.resize((337,600))\n",
    "    img_array = (np.array(im).astype(np.float32))\n",
    "            #Expand dimensions to match the 4 D Tensor shape.\n",
    "    \n",
    "    frame=imutils.resize(frame, width=600)\n",
    "    H,W=frame.shape[:2]\n",
    "    print(\"height: {}, width: {}\".format(H,W))\n",
    "    if (fc==0 or fc%4==0):\n",
    "        rects=detect_boxes(img_array, detect_fn,thresh,H,W)\n",
    "#         rect_mask=np.array(list(map(func,rects)))>thresh\n",
    "#         print(rects)\n",
    "#         print(rect_mask)\n",
    "#         valid_rects=rects[rect_mask]\n",
    "        tracker.objects=tracker.update(frame,rects,thresh)\n",
    "       \n",
    "    else:\n",
    "        t_rects=tracker.track_update(frame)\n",
    "#         rect_mask=np.array(list(map(func,t_rects)))>thresh\n",
    "#         print(rects)\n",
    "#         print(rect_mask)\n",
    "#         valid_rects=t_rects[rect_mask]  \n",
    "#         print(\"tracked_valids: \\n {}\".format(valid_rects))\n",
    "        tracker.objects=tracker.update(frame,t_rects,thresh)\n",
    "            \n",
    "    #Performing Liveness test for antispoofing and \n",
    "    #implementing face recognition per face tracked\n",
    "    for i in tracker.objects.values():\n",
    "        i.box_recognize(frame,class_model,label_map,tracker)\n",
    "    image=visualize_boxes(frame,tracker.objects)\n",
    "    y_stat=20\n",
    "    for item,count in tracker.count.items():\n",
    "        cv2.putText(image,'{}: {}'.format(item,count),(0,y_stat),cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 0), 2)\n",
    "        y_stat+=20\n",
    "    blk = np.zeros(image.shape, np.uint8)\n",
    "    cv2.rectangle(blk, (int(0.45*W),0), (int(0.55*W), 337), (0, 255, 0), -1)\n",
    "    res = cv2.addWeighted(image,1, blk, 0.25, 1)\n",
    "\n",
    "    # Putting the image back to its position\n",
    "    res=imutils.resize(res,width=1200)\n",
    "    cv2.imshow('faces',res)\n",
    "    fc+=1\n",
    "    end=time.time()\n",
    "    print(\"FPS: {}\".format(1/(end-start)))\n",
    "    FPS.append(int(1/(end-start)))\n",
    "    print(tracker.objects.keys())\n",
    "    if cv2.waitKey(10) & 0xff==ord('q'):\n",
    "        print(\"STOPPING APPLICATION\")\n",
    "        \n",
    "        break\n",
    "print(\"MEAN FPS THROUGHOUT VIDEO: {}\".format(np.array(FPS).sum()/len(FPS)))        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28745b97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a3c435",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381a1810",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchenv",
   "language": "python",
   "name": "torchenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
